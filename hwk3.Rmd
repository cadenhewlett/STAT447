---
title: "STAT 447 Assignment 3"
author: "Caden Hewlett"
date: "`r Sys.Date()`"
header-includes:
   - \usepackage{bbm}
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(extraDistr)
library(ggplot2)
library(pracma)
```


# Question 1 : Functions on the Unit Interval

For this question, use Simple Monte Carlo. The main twist compared to week one is that you will use a continuous random variable.


## Part 1

Write a function called `mc_estimate` that takes a function $f : [0, 1] \rightarrow \mathbb{R}$ and outputs the Monte Carlo estimator of $\int_0^1 f(x)dx$ using $n = 100,000$ independent samples from $\text{unif}(0, 1)$.

**NOTE:** Because my computer could handle it, I used $M = 100,000$ rather than $M = 10,000$ just for fun. The results are similar (but obviously more precise for larger $M$.)

**Solution**

The function is created using the code below:
```{r mc_estimate}
mc_estimate <- function(f){
  # declare the number of iterations
  M <- 100000
  # randomly generate M total observations in [0, 1]
  m_vals <- runif(M)
  # then, for all m in random generations, evaluate f(m)
  G_m <- f(m_vals)
  # then compute the average
  G_hat_m <- (1/M)*sum(G_m)
  # and return
  return(G_hat_m)
}
```

## Part 2

Consider the function $f: [0, 1] \rightarrow [0, \infty)$ given by:

$$
f(x) = \dfrac{1}{\sqrt[3]{x^2(1- x)}}
$$
Note, importantly, that 

$$
\mathcal{I}_1 =\int_0^1 f(x)\text{d}x = \dfrac{\pi}{\sin\left(\frac{\pi}{3}\right)}
$$
Test your implementation of `mc_estimate` by checking that it produces an answer close to the value above.

**Solution**

We'll start by computing the actual result:

```{r equation1result}
expected = pi / (sin(pi/3))
expected
```

Now, we implement `mc_estimate`.

```{r test_mc}
# Apollo 11 moon landing, as an integer
set.seed(19690720)

f <- function(x){
  1 / ( ((x^2)*(1 - x))^(1/3) )
}

observed <- mc_estimate(f)
observed
```

It seems we got pretty close! Let's calculate the percent difference.

```{r perc_diff_1}
(abs(observed - expected) / expected)*100
```

It looks like there's about a $0.05\%$ difference between $\hat{G}_M$ for $M = 100,000$.

For completeness, I also ran the code with $M = 10,000$ and observed approximately a $2.52\%$ difference. 

## Part 3

The following integral, known as the sine integral, does not admit a closed-form expression. 

$$
\mathcal{I}_2 = \int_0^1 \dfrac{\sin(t)}{t}\text{d}t
$$

It does not admit a closed-form expression. Estimate its value using `mc_estimate(f)`.


**Solution**


To test our Monte Carlo Approximation, we will evaluate $\text{Si}(1)$ using the `pracma` package.

```{r six}
Si(1)
```

Now, we can see how close our `mc_estimate` gets. We let $g(x) = \frac{\sin(x)}{x}$.

```{r test_six}
set.seed(19690720)

g <- function(x){
  sin(x) / x
}
observed = mc_estimate(g)
observed
```

It looks like we got really close! Let's find the percent difference:
```{r perc_diff}
expected = Si(1)
# we overwrite our old variables for convenience (and memory)
(abs(observed - expected) / expected)*100
```

It looks like there's about a $0.03\%$ difference between $\hat{G}_M$ for $M = 100,000$.

For completeness, I also ran the code with $M = 10,000$ and observed approximately a $0.09\%$ difference. 

# Question 2 :  Implementing SNIS for simPPLe

## Part 1

First, install the package `distr`.

Since this is a `.Rmd` file, all packages are loaded at the beginning in a hidden cell with suppressed warnings.

```{r verify_install}
"distr" %in% installed.packages()
```
## Part 2 

Read this short tutorial on `distr`. Nothing to submit for this item.

For completeness, I will work through the tutorial on my own and place the results here.

```{r distr_playground}
# Commented out to avoid spamming outputs
# distPoisson <- Pois(lambda = 3.2)
# 
# d(distPoisson)(2)
# 
# sum(r(distPoisson)(10))
# 
# d(sqrt(distPoisson))(2)
```


## Part 3

Read the “scaffold code”, and use `distr` and two of the functions in the example to create a fair coin, flip it, and to compute the probability of that flip:


## Part 4

Complete the implementation of the function `posterior`:

```{r posterior_fun}
posterior = function(ppl_function, number_of_iterations) {
  numerator = 0.0
  denominator = 0.0
  for (i in 1:number_of_iterations) {
    weight <<- 1.0
    # update numerator and denominator
  }
  return(numerator/denominator)
}
```

## Part 5

Test your program by checking that you can approximate the posterior probability of the fair coin obtained in exercise 1, Q.2.