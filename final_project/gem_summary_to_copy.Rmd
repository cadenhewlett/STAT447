---
title: "GEM Process"
author: "Caden Hewlett"
date: "`r Sys.Date()`"
output: pdf_document
header-includes:
   - \usepackage{bbm}
   - \usepackage{upgreek}
   - \usepackage{booktabs}
   - \usepackage{bbm}
   - \usepackage{mathrsfs}
   - \usepackage{yfonts}
bibliography: bibliography.bib
---
(separate file for easy merge)


## Implementation: GEM Distribution

<!-- https://courses.engr.illinois.edu/cs598jhm/sp2013/Slides/Lecture13.pdf -->
<!-- https://www.cs.cmu.edu/~epxing/Class/10708-14/scribe_notes/scribe_note_lecture20.pdf -->
In order to properly implement a DPMM, we must establish some finite approximation. There are many methods to finitely approximate a pull from $\text{DP}(\alpha \mathbb{G}_0)$ distribution, however the most approachable and the approach implemented in the software applied in this work is known as a stick-breaking or a Griffiths, Engen, and McCloskey (GEM) distribution. The purpose of the GEM distribution in terms of a Dirichlet Process is to generate weights $\{\pi_k\}$ of the mixture components. 
<!-- We'll discuss this in more detail in the sections to follow.  -->

The general idea behind a GEM Distribution is to  take a "stick" with unit length and break it at a location decided by a $\upbeta_1 \sim \text{beta}(1, \alpha)$ random pull, which I will denote $\pi_1$. Then, we break the remaining stick length in two by a second $\upbeta_2 \sim \text{beta}(1, \alpha)$ random pull. Hence, $\pi_2 = (1 - \upbeta_1)\upbeta_2$, which can be understood as "the remaining stick length after the first break, broken at the second random break location." Then, we can generalize this idea for $k = 1, 2, \dots, K$ to yield the form of a GEM distribution as follows:
$$
\uppi \sim \text{GEM}(\alpha): \text{Let } \upbeta_k \overset{\text{iid}}\sim \text{beta}(1, \alpha), \text{ then } \pi_k = \upbeta_k \prod_{i=1}^{k-1}(1 - \upbeta_i)
$$
Where $\pi_k$ can be considered the $k$-th value returned from the GEM distribution; we know that $\text{GEM}(\alpha)$ is a valid discrete distribution since the $\pi_k$ values sum to one [@Xing2014]. Critically, the sole parameter $\alpha$, known as the "concentration" controls the sampled measure variability in the finite-approximated Dirichlet Process.  A higher $\alpha$ indicates less confidence in the base measure yielding greater dispersion and a higher number of clusters. Conversely, a lower $\alpha$ indicates more confidence in $\mathbb{G}_0$ resulting in fewer, larger clusters. [@Sethuraman1994]. This property can be seen in Figure 1. 
