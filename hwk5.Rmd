---
title: "STAT 447 Assignment 5"
author: "Caden Hewlett"
date: "`r Sys.Date()`"
header-includes:
   - \usepackage{bbm}
   - \usepackage{upgreek}
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(extraDistr)
library(ggplot2)
library(pracma)
library(distr)
library(latex2exp)
library(knitr)
source("scaffold.R")
source("simple.R")
source("simple_utils.R")
```

<!-- Will the posterior be discrete? I think so.  -->
# Question 1: Sequential Updating

Consider a joint a joint probabilistic model given by
$$
\theta \sim \rho, \text{ and } (x_i \mid \theta) \; \overset{iid}{\sim} \nu_{\theta}, \text{ where } i \in \{1, 2, \dots , n\}
$$
 
where $\rho$ is a prior distribution for the unknown parameter $\theta$, and $\{x_i\}_{i=1}^n$ is a sequence of observations with conditional distribution $\nu_{\theta}$.

## Part 1

Write down the posterior distribution of $\theta$ given $\{x_i\}_{i=1}^n$.

In a more verbose sense, let $\Theta$ be the random variable for the unknown parameter, and $\theta$ be the realization of this random variable under the proposed prior distribution. We can then write the following (*purely for nomenclature reasons*)

$$
\rho = p_{\Theta}(\theta), \text{ where } p_{\Theta}(\theta) \text{ is the PMF/PDF given by } \rho
$$
$$
P(X = x \mid \theta ) = p_{X \mid \Theta}(x, \theta), \text{ where } p_{X \mid \Theta}(x, \theta) \text{ is the PMF given by } \nu_{\theta}
$$
With this in mind, we can write the posterior of $\theta$ given $\{x_i\}_{i=1}^n$, where we describe the event that $\{X_i\}_{i=1}^n = \{x_i\}_{i=1}^n$ using Bayes' Rule.

We will begin by using the most verbose notation possible, for complete clarity.
$$
P(\Theta =\theta \mid \{X_i\}_{i=1}^n = \{x_i\}_{i=1}^n) = \dfrac{p_{\Theta}(\theta)P\big(\{X_i\}_{i=1}^n = \{x_i\}_{i=1}^n \mid \Theta =\theta\big)}{P\big(\{X_i\}_{i=1}^n  = \{x_i\}_{i=1}^n\big)}
$$
We start by considering the joint likelihood function.
$$
P\big(\{X_i\}_{i=1}^n = \{x_i\}_{i=1}^n \mid \Theta =\theta\big) = P\big((X_n = x_n, X_{n-1} = x_{n - 1}, \dots, X_1 = x_1) \mid \Theta = \theta \,)
$$
Then, using intersections, we can write the likelihood as:
$$
P\big(\{X_i\}_{i=1}^n = \{x_i\}_{i=1}^n \mid \Theta =\theta\big) = P\Big(  \bigcap_{i = 1}^n  (X_i = x_i) \mid \Theta = \theta \Big)
$$
Now, we use the following property of *iid* random variables
$$
\text{I.I.D} \implies \forall (i \neq j) \in [1,n], \; (X_i \mid \Theta) \perp (X_j \mid \Theta) \implies \forall (i \neq j) \in [1,n], P(X_i \cap X_j \mid \Theta) = P(X_i \mid \Theta)P(X_j \mid \Theta)
$$
Hence, we can write the likelihood as:
$$
P\big(\{X_i\}_{i=1}^n = \{x_i\}_{i=1}^n \mid \Theta =\theta\big) = \prod_{i = 1}^n \Big( P(X_i = x_i \mid \Theta = \theta ) \Big) = \prod_{i = 1}^n(\nu_{\theta}) = (\nu_\theta)^n
$$
Which, as you can see, simplifies nicely to $(\nu_{\theta})^n$.

Now, our expression simplifies a little bit to the following:
$$
P(\Theta =\theta \mid \{X_i\}_{i=1}^n = \{x_i\}_{i=1}^n) = \dfrac{p_{\Theta}(\theta)\nu_{\theta}^n}{P\big(\{X_i\}_{i=1}^n  = \{x_i\}_{i=1}^n\big)}
$$
If we wished to, we could write the following proportionality directly to conclude:
$$
p_{\Theta \mid {X}_{1:n}}(\theta, \{x_i\}_{i=1}^n)  =\uppi_n \propto \rho\cdot\nu_{\theta}^n
$$
Or, letting normalizing constant $\mathcal{Z}_{1:n} = P\big(\{X_i\}_{i=1}^n  = \{x_i\}_{i=1}^n\big)$, we can write:
$$
\uppi_n(\theta) = \dfrac{\rho\cdot\nu_{\theta}^n}{P\big(\{X_i\}_{i=1}^n  = \{x_i\}_{i=1}^n\big)} = ({\mathcal{Z}^{-1}_{1:n}})\cdot{\rho\cdot\nu_{\theta}^n}
$$
Giving us a nice expression for the posterior, both in proportionality and equality according to a normalizing constant.
<!-- (x_i \mid \theta) \; \overset{iid}{\sim} \nu_{\theta}, \text{ where } i \in \{1, 2, \dots , n\} -->

## Part 2

Suppose now we get an additional data point $x_{n + 1}$ with the same conditional distribution $\nu_{\theta}$. Show that using the posterior from part 1 as the *prior* and data equal to just $x_{n + 1}$ gives the same posterior distribution as redoing part 1 with the $n + 1$ data points.

We wish to show that:
$$
\uppi_{(n + 1)}(\theta) = \dfrac{p_{\Theta}(\theta)P\big(\{X_i\}_{i=1}^{n+1} = \{x_i\}_{i=1}^{n+1} \mid \Theta =\theta\big)}{P\big(\{X_i\}_{i=1}^{n+1}  = \{x_i\}_{i=1}^{n+1}\big)} = \dfrac{\uppi_n(\theta)P(X_{n+1} = x_{n+1} \mid \Theta = \theta)}{P(X_{n+1} = x_{n+1})}
$$
We'll evaluate each expression in turn.

With the first term, we can say directly that:
$$
\text{LHS}= \dfrac{p_{\Theta}(\theta)P\big(\{X_i\}_{i=1}^{n+1} = \{x_i\}_{i=1}^{n+1} \mid \Theta =\theta\big)}{P\big(\{X_i\}_{i=1}^{n+1}  = \{x_i\}_{i=1}^{n+1}\big)} = (\mathcal{Z}_{1:(n+1)}^{-1}) \cdot \rho \cdot \nu_{\theta}^{n+1}  \propto \rho \cdot \nu_{\theta}^{n+1}
$$
By the exact process used in **Part 1**.

More interestingly, we can expand the second term to as follows:
$$
\uppi_{(n+1)}(\theta) = \dfrac{\uppi_n(\theta)P(X_{n+1} = x_{n+1} \mid \Theta = \theta)}{P(X_{n+1} = x_{n+1})} = (\mathcal{Z}_{n+1}^{-1})\uppi_n(\theta) \nu_{\theta}
$$
Then, substituting our expression for $\uppi_n(\theta)$ from **Part 1**:
$$
\text{RHS} =  (\mathcal{Z}_{n+1}^{-1})\Big(({\mathcal{Z}^{-1}_{1:n}})\cdot{\rho\cdot\nu_{\theta}^n} \Big)\nu_{\theta} = \big(\mathcal{Z}_{n+1}^{-1} \cdot{\mathcal{Z}^{-1}_{1:n}} \big)\rho \big(\nu^n \cdot \nu^1) = (\mathcal{Z}_{n+1} \cdot{\mathcal{Z}_{1:n}})^{-1} \rho \cdot \nu_{\theta}^{n+1} \propto \rho \cdot \nu_{\theta}^{n+1}
$$
Now, consider the following Lemma which we will use without proof.

**Lemma** 

Let $f(y)$ and $g(y)$ be probability distributions acting on the same space $y \in {Y}$. Let 
$$
\exists c \in \mathbb{R}^{+} \text{ s.t. } \forall y \in Y, f(y) = c \cdot  g(y) \implies f \text{ and }g \text{ describe equivalent distributions.}
$$
In our specific case, we have:
$$
(\mathcal{Z}_{1:(n+1)})^{-1} {\text{LHS}} = (\mathcal{Z}_{n+1}\cdot{\mathcal{Z}_{1:n}})^{-1}{\text{RHS}}
$$
So, we can write:
$$
\text{Let } c = \dfrac{(\mathcal{Z}_{n+1} \cdot{\mathcal{Z}_{1:n}})^{-1}}{(\mathcal{Z}_{1:(n+1)})^{-1}} = \dfrac{\mathcal{Z}_{1:(n+1)}}{\mathcal{Z}_{n+1} \cdot{\mathcal{Z}_{1:n}}}, \text{ then } \text{LHS} = c\cdot\text{RHS}
$$
Which would imply that the two are equivalent under proportionality, and, assuming $c \in \mathbb{R}^{+}$, are equivalent under normalization. 

# Question 2: Bayesian Inference in the Limit of Increasing Data

We will use the tractability of the coin bag example to explore the behavior of the posterior distribution as the number of observations goes to infinity. Recall that its joint distribution is
$$
\begin{aligned}
p &\sim {\mathrm{discrete}}(\{0,1/K,2/K,\dots,1\},\rho) \\
y_i|p &\overset{\text{iid}}{\sim}{\mathrm{bern}}(p), \quad i\in\{1,\dots,n\}
\end{aligned}
$$
Where $\rho = (\rho_0, \rho_1, \dots, \rho_K)$ is the prior, where $\forall k \in [1,K]$ the proportion of coins of type $k$ in the bag is $\rho_k$. For the sake of notation (and to avoid confusion with capital $P$), we will let $p_{\text{obs}}$ be a realization of the random variable $p$. 

## Part 1

The following simulates the posterior for the above equation.
```{r}
posterior_distribution = function(rho, n_heads, n_observations) {
  K = length(rho) - 1
  gamma = rho * dbinom(n_heads, n_observations, (0:K)/K)
  normalizing_constant = sum(gamma)
  gamma/normalizing_constant
}
```

Note, we can verify that passing the following gives our familiar $1/17$ result from Assignment 1.
```{r}
assign_1 = posterior_distribution(c(0, 0.5, 1),  3,  3)
# check
all.equal( 1/17, assign_1[2], tolerance = 2e-10)
```
## Part 2

Write a function `posterior_mean` that computes the posterior mean given the output of `posterior_distribution`.

We recall that the posterior mean is computed as follows:
$$
\mathbb{E}(p \mid Y = y)= \sum_{\{p\, : \,\uppi(p) > 0 \}}p\,\uppi(p)
$$
From our "original" coin flip example, we'd have $K=2$ and
$$
\mathbb{E}(p \mid Y = y) = \Big(\dfrac{1}{K}\Big) \pi(1) + \Big(\dfrac{2}{K}\Big) \pi(2) = \Big(\dfrac{1}{2}\Big)\cdot\dfrac{1}{17} + \Big(\dfrac{2}{2}\Big) \dfrac{16}{17} = \frac{33}{34}
$$
Which we will use to test our function. 

```{r}
posterior_mean <- function(pi){
  K = length(pi)-1
  return(sum(((0:K)/K)*pi))
}
all.equal(posterior_mean(assign_1), 33/34)
```
Further, we'd expect a posterior mean of $1$ in the case where all the weight was put on the $1$ ("always heads") coin.

```{r}
posterior_mean(posterior_distribution(c(0,0,1), 5, 5))
```

## Part 3

Write another function called `simulate_posterior_mean_error`.

It will perform the following tasks:

a.) Simulate $p_{\text{true}} \sim \text{discrete}(\{0, 1/K, \dots, K/K\}, \rho_{\text{true}})$, where $\rho_{\text{true}}$ is supplied to the function.

This is done as follows (using the Assignment 1 coin flip example)
```{r}
rho_true = c(0, 0.5, 1)/sum(c(0, 0.5, 1)); 
K = length(rho_true)-1
p_true <- DiscreteDistribution(supp = (0:K)/K, rho_true)
p_true_obs = simulate(p_true)
p_true_obs
```
b.) Simulates $\{y_i\}_{i = 1}^{n_{\text{obs}}} = \{y_1, y_2, \dots, y_{n_{\text{obs}}}\} = y_{1:n_{\text{obs}}}$ conditional on the simulated $p_{\text{true}}$. We recall that $\forall i \in [1, n_{\text{obs}}], (y_i \mid p_{\text{true}}) \sim \text{bern}(p_{\text{true}})$, where it should be noted that $n_{\text{obs}} = $`n_observations` is supplied to the function.

```{r}
n_observations = 3
n = n_observations
y_obs = rbern(n, p_true_obs)
y_obs
```

c.) Calls `posterior_distribution` using and the simulated data. Note that $\rho_{\text{prior}}$ is the final parameter to the function.
```{r}
# in the coin flip, we assumed all were equally likely
rho_prior = c(1, 1, 1)
pi_obs = posterior_distribution(
  rho_prior, sum(y_obs), 3
)
pi_obs
```
d.) Computes the posterior mean $\mathbb{E}(p \mid y_{\text{obs}})$, given the observed posterior $\uppi_{\text{obs}}(p)$.

```{r}
post_mean = posterior_mean(pi_obs)
post_mean
```
e.) Compute the absolute error $\varepsilon_{\text{obs}}$ $$\varepsilon_{\text{obs}} = \big|p_{\text{true}} - \mathbb{E}(p \mid y_{1:n_{\text{obs}}})\big|$$.
```{r}
epsilon_obs = abs(p_true_obs - post_mean)
epsilon_obs
```
Then we combine this all into one process
```{r simulate_posterior_mean_error}
set.seed(200)
simulate_posterior_mean_error = function(rho_true, rho_prior, n_observations){
  # step 1
  p_true = DiscreteDistribution(supp = (0:K)/K, rho_true)
  p_true_obs = simulate(p_true)
  # print(p_true_obs)
  # step 2
  epsilons = c()
  for (value in n_observations){
    y_obs = rbern(value, p_true_obs)
    # step 3
    pi_obs = posterior_distribution(rho_prior, sum(y_obs), value)
    post_mean = posterior_mean(pi_obs)
    # step 4
    epsilons = c(epsilons, abs(p_true_obs - post_mean))
  }
  return(epsilons)
}
# plot(simulate_posterior_mean_error(rho_true, rho_prior, 1:1000), type = 'l')
```
```{r testzone}
```
## Part 4

Now, we use the following setup, normalizing the given $\rho$ values so it can work with the `DiscreteDistribution` function.
```{r}
K = 100
rho_true = rho_prior = rep(1, K+1) / (K+1)
```

Applying it to each $n \in  \{1,  2,  4,  8, 16, 32, 64\}$
```{r}
n_obs_vector <- 2^(0:6)
simulate_posterior_mean_error(rho_true, rho_prior, n_obs_vector)
```
Repeating each case $M = 1,000$ times.

```{r simulations}
set.seed(101)
M = 1000
rsf = c()
for (m in 1:M){
  rsf = c(rsf, simulate_posterior_mean_error(rho_true, rho_prior, n_obs_vector))
}
experiment_results = data.frame(errors = matrix(rsf))
experiment_results$replication = rep(1:M, each = 7)
experiment_results$n_observations = rep(n_obs_vector, times = M)
```


Then we can display the `head` and `tail` of this data frame. 
```{r}
kable(head(experiment_results))
kable(tail(experiment_results))
```

## Part 5

Visualize the above data using a log-log plot using the following code:
```{r}
ggplot(experiment_results, aes(x=n_observations, y=errors+1e-9)) + # avoid log(0)
  stat_summary(fun = mean, geom="line") + # Line averages over 1000 replicates
  scale_x_log10() +  # Show result in log-log scale
  scale_y_log10(n.breaks=16) +
  coord_cartesian(ylim = c(1e-3, 1)) +
  theme_minimal() +
  geom_point() +
  labs(x = "Number of observations",
       y = "Absolute error of the posterior mean")
```

## Part 6

We'll estimate the slope with the following function, again letting $\varepsilon$ be the error. 
$$
\hat{m} = \frac{y_7-y_5}{x_7-x_5} =  \frac{\log_{10}(\bar{\varepsilon}_7) - \log_{10}(\bar{\varepsilon}_5)}{\log_{10}(n_7)-\log_{10}(n_5)} 
$$

Where, as shown above, $x$  is  $\log_{10}(n_i)$, is $y$  is  $\log_{10}(\bar{\varepsilon}_i)$, where $\bar{\varepsilon}$ is the mean absolute error of the posterior mean and the subscript indicates the column of points from left to right. 


```{r}
x7 = log10(n_obs_vector[7])
x5 = log10(n_obs_vector[5])
y7 = log10(mean(experiment_results$errors[
            experiment_results$n_observations == n_obs_vector[7]]))
y5 = log10(mean(experiment_results$errors[
            experiment_results$n_observations == n_obs_vector[5]]))
# y7 = log10( mean(all_simulations[, 7]) )
# y5 = log10( mean(all_simulations[, 5]) )
# 
#head(experiment_results)
m = (y7 - y5)/(x7 - x5)
m
```
What can you deduce about the scaling law of the error?

Well, if we recall the notation of $y = mx + b$, the slope $m$ can be employed linearly as  
$$
\log_{10}(\bar{\varepsilon}_i) = \hat{m}\log_{10}(n_i) + c, \text{ for some c }\in \mathbb{R}$$
Then, by rearrangement, we would have:
$$
\bar{\varepsilon}_i = C n_i^{\hat m}, \text{ where } C = 10^c.
$$
Notably, our slope is negative. Assuming $C$ is negligible for the relationship between the variables, we can write the error values as:
$$
\bar{\varepsilon}_i \propto  n_i^{-\hat m} \approx n_i^{-0.46} 
$$
From this approximate relationship, to achieve an additional one decimal point of accuracy in $\bar{\varepsilon}_i$ for a given index $i$ of the vector of $\vec{n}$ observation we need to solve the following for $k$:
$$
0.10\bar{\varepsilon} = 0.10(n_i^{-0.46})  = (k n_i)^{-0.46}
$$
Simplifying we see:
$$
0.10(n_i^{-0.1})  = (k)^{-0.46}(n_i^{-0.1}), \text{ hence } 0.10 = (k)^{-0.46}
$$
$$
\log_{10}(0.10) = -0.46\log_{10}(k), \; \therefore k = 10^{1/0.46} = 151.6115 \approx 150
$$

This means that - assuming my math here is correct and the approximation is decent - in order to increase the accuracy of $\bar{\varepsilon}$ by an additional decimal point the sample size must be increased by a factor of approximately $150$.

We made quite a few simplifying assumptions for this metric, and the precise calculations here could be wrong. The larger point is to demonstrate that the scaling law of the error declines at a very slow rate. 

## Part 7

We repeat Part 4, but now we have the following:

```{r}
rho_true = rep(1, K+1) 
rho_true = rho_true/sum(rho_true)
rho_prior = 1:(K+1)
rho_prior = rho_prior/sum(rho_prior)
```

Our simulation is here (to be called `new_results`.)

```{r}
rsf = c()
for (m in 1:M){
  rsf = c(rsf, simulate_posterior_mean_error(rho_true, rho_prior, n_obs_vector))
}
new_results = data.frame(errors = matrix(rsf))
new_results$replication = rep(1:M, each = 7)
new_results$n_observations = rep(n_obs_vector, times = M)
```

Then, we can plot the results. First, however we must make a unified data frame called `all_results`.
```{r}
new_results$prior_type = "Different"
experiment_results$prior_type = "Match"
all_results = rbind(experiment_results, new_results)
```
Now, we can make the unified plot.
```{r}
ggplot(all_results, aes(x=n_observations, y=errors+1e-9, # avoid log(0) 
                        color=prior_type, shape=prior_type)) + 
  stat_summary(fun = mean, geom="line") + # Line averages over 1000 replicates
  scale_x_log10() +  # Show result in log-log scale
  scale_y_log10(n.breaks=16) +
  coord_cartesian(ylim = c(1e-3, 1)) +
  theme_minimal() +
  geom_point() +
  labs(x = "Number of observations",
       y = "Absolute error of the posterior mean")
```

The main visual difference is the faster convergence rate of the "Different" plot in absolute error difference. In other words, the errors begin larger for small $n$, but converge to nearly the same value by the time we reach $n_7$. This implies that the even a prior that is very different from $\rho_{\text{true}}$ will converge in $\varepsilon$ to the "correct" $\rho_{\text{prior}} = \rho_{\text{true}}$ error rate.

This initial "ramping down" of the error rate for the "Different $\rho$" plot makes sense, as the posterior expectation of the incorrect model will quickly approach the true value $p_{\text{true}}$ as $n\uparrow$, regardless of the prior (by the nice properties of Bayesian methods we have discussed often in this course.). Then, the remaining difference between both models is due to the "simulation error", which will slowly converge by the reasoning discussed in the previous question.